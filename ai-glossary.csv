Target Category,Category,Term,,Short Definition,Why It Matters
Basics,Hamel's list,AGI (Artificial General Intelligence),"AI that can do any intellectual task a human can. ◆ While some define AGI as AI that’s as smart as a human in every way, this isn’t something you need to focus on right now. It’s more important to build AI solutions that solve your specific problems today.",AI that can do any intellectual task a human can.,"While some define AGI as AI that’s as smart as a human in every way, this isn’t something you need to focus on right now. It’s more important to build AI solutions that solve your specific problems today."
Basics,Basics,"AI (Aritificial Intelligence)
syn: model, LLM","A language model like ChatGPT ◆ Colloquially we say AI to refer to the current generation LLMs / models. The field of AI is broad and spans decades, covers Machine Learning, Computer Vision, Speech recognition, AGI, Robotics, etc.",A language model like ChatGPT,"Colloquially we say AI to refer to the current generation LLMs / models. The field of AI is broad and spans decades, covers Machine Learning, Computer Vision, Speech recognition, AGI, Robotics, etc."
Basics,Pre training,"Assistant / Instruct model
Rel: Shoggoth with pink mask","A base model that has been fine-tuned to be a honest, harmless, and helpful assistant. ◆ This is the type of model most people interact with. The fine-tuning process is what makes it useful for real-world tasks.","A base model that has been fine-tuned to be a honest, harmless, and helpful assistant.",This is the type of model most people interact with. The fine-tuning process is what makes it useful for real-world tasks.
Basics,Pre training,"Base model
Rel: Shoggoth","A powerful text-completion engine but not a conversational assistant. ◆ There are only 10s of these out there because they're prohibitively expensive to train. They are foundational building blocks that can be customised, and taught new skills or behaviours.",A powerful text-completion engine but not a conversational assistant.,"There are only 10s of these out there because they're prohibitively expensive to train. They are foundational building blocks that can be customised, and taught new skills or behaviours."
Remove,Post training,Post-training,"The second phase of LLM creation, where a pre-trained base model is adapted to become a helpful, instruction-following assistant. ◆ This stage bridges the gap between a raw ""internet simulator"" and a useful tool like ChatGPT, aligning the model with human intent.","The second phase of LLM creation, where a pre-trained base model is adapted to become a helpful, instruction-following assistant.","This stage bridges the gap between a raw ""internet simulator"" and a useful tool like ChatGPT, aligning the model with human intent."
Remove,Pre training,Pre-training,"The initial stage of building an LLM, where a neural network learns from a vast dataset of text from the internet. ◆ This is where the model gains its foundational knowledge about language, facts, and reasoning. The massive scale of this stage is what gives LLMs their broad capabilities.","The initial stage of building an LLM, where a neural network learns from a vast dataset of text from the internet.","This is where the model gains its foundational knowledge about language, facts, and reasoning. The massive scale of this stage is what gives LLMs their broad capabilities."
Remove,Hamel's list,Pre-training,"The model’s initial learning phase on lots of data. ◆ It’s like giving the model a big education before it starts specific jobs. This helps it learn general things, but you might need to adjust it later for your needs.",The model’s initial learning phase on lots of data.,"It’s like giving the model a big education before it starts specific jobs. This helps it learn general things, but you might need to adjust it later for your needs."
Remove,Hamel's list,Prompt Engineering,"Designing prompts to get the best results. ◆ By learning how to write good prompts, you can make the AI give better answers. It’s like improving your communication skills to get the best results.",Designing prompts to get the best results.,"By learning how to write good prompts, you can make the AI give better answers. It’s like improving your communication skills to get the best results."
Remove,Hamel's list,Prompt Injection,A security risk where bad instructions are added to prompts. ◆ Users might try to trick the AI into ignoring your rules and doing things you don’t want. Knowing about prompt injection helps you protect your AI system from misuse.,A security risk where bad instructions are added to prompts.,Users might try to trick the AI into ignoring your rules and doing things you don’t want. Knowing about prompt injection helps you protect your AI system from misuse.
Remove,Hamel's list,Prompt Templates,Pre-made formats for prompts to keep inputs consistent. ◆ They help you communicate with the AI consistently by filling in blanks in a set format. This makes it easier to use the AI in different situations and ensures you get good results.,Pre-made formats for prompts to keep inputs consistent.,They help you communicate with the AI consistently by filling in blanks in a set format. This makes it easier to use the AI in different situations and ensures you get good results.
Remove,Reinforcement Learning (RL),Reinforcement Learning from Human Feedback (RLHF),"A technique that uses human preferences to train a ""reward model"" which then guides the reinforcement learning process. ◆ RLHF is the key that unlocks RL for subjective, unverifiable domains like writing quality or helpfulness. It's used to fine-tune most modern chatbots.","A technique that uses human preferences to train a ""reward model"" which then guides the reinforcement learning process.","RLHF is the key that unlocks RL for subjective, unverifiable domains like writing quality or helpfulness. It's used to fine-tune most modern chatbots."
Remove,Hamel's list,Agents,"AI models that can perform tasks or run code without human help. ◆ Agents can automate complex tasks by making decisions and taking actions on their own. This can save time and resources, but you need to watch them carefully to make sure they are safe and do what you want.",AI models that can perform tasks or run code without human help.,"Agents can automate complex tasks by making decisions and taking actions on their own. This can save time and resources, but you need to watch them carefully to make sure they are safe and do what you want."
Basics,Pre training,"Context
Rel: Context engineering","Same as prompt, but usually refers to the relevant information that's necessary to answer the question or perform the task ◆ It is the biggest lever in influencing the AI's response. The context is the model's ""short-term memory"" and it limits the complexity of tasks it can perform.","Same as prompt, but usually refers to the relevant information that's necessary to answer the question or perform the task","It is the biggest lever in influencing the AI's response. The context is the model's ""short-term memory"" and it limits the complexity of tasks it can perform."
,,,,,
Basics,Hamel's list,Hallucination,"When AI makes up things that aren’t true. ◆ AIs sometimes make stuff up, and you can’t completely stop this. It’s important to be aware that mistakes can happen, so you should check the AI’s answers.",When AI makes up things that aren’t true.,"AIs sometimes make stuff up, and you can’t completely stop this. It’s important to be aware that mistakes can happen, so you should check the AI’s answers."
Basics,Hamel's list,Inference,"Getting an answer back from the model. ◆ When you ask the AI a question and it gives you an answer, that’s called inference. It’s the process of the AI making predictions or responses. Knowing this helps you understand how the AI works and the time or resources it might need to give answers.",Getting an answer back from the model.,"When you ask the AI a question and it gives you an answer, that’s called inference. It’s the process of the AI making predictions or responses. Knowing this helps you understand how the AI works and the time or resources it might need to give answers."
Basics,Pre training,Neural Networks,Computational models inspired by the brain's structure ◆ They are the core technology that enables AI to learn from text and generate human-like responses.,Computational models inspired by the brain's structure,They are the core technology that enables AI to learn from text and generate human-like responses.
Basics,Hamel's list,Prompt,"The input or question you give to the AI. ◆ Giving clear and detailed prompts helps the AI understand what you want. Just like talking to a person, good communication gets better results.",The input or question you give to the AI.,"Giving clear and detailed prompts helps the AI understand what you want. Just like talking to a person, good communication gets better results."
Basics,Pre training,Stochastic,"AI's Nature of being probabalistic, rolling the dice ◆ This is why you can get a different answer every time you ask the same question. It allows for creativity but also unpredictability.","AI's Nature of being probabalistic, rolling the dice",This is why you can get a different answer every time you ask the same question. It allows for creativity but also unpredictability.
Basics,Post training,System Prompt,"A hidden instruction given to the model about its persona, rules, and identity. ◆ It's a powerful way to steer the AI's behavior consistently without the user seeing the underlying instructions.","A hidden instruction given to the model about its persona, rules, and identity.",It's a powerful way to steer the AI's behavior consistently without the user seeing the underlying instructions.
Basics,Pre training,"Tokens
Rel: tokenisation, encoding, vocabulary","The pieces of text that a model understands, it can be a word, a part of a word, or a character. ◆ Token impacts model abilities, especially with tasks like spelling or character manipulation. Also, you pay for AI based on the number of tokens used, so knowing about tokens helps manage costs. The vocabulary of tokens depends on training data, and it impacts performance in multilingual or esoteric domains.","The pieces of text that a model understands, it can be a word, a part of a word, or a character.","Token impacts model abilities, especially with tasks like spelling or character manipulation. Also, you pay for AI based on the number of tokens used, so knowing about tokens helps manage costs. The vocabulary of tokens depends on training data, and it impacts performance in multilingual or esoteric domains."
Remove,Pre training,Encoding,"The process of converting data from a human-readable format (e.g., text, images, audio) into a numerical representation that a machine learning model can process.	 ◆ AI models operate on numbers, not raw data like pixels or characters. Encoding is the crucial bridge that translates real-world information into a mathematical format the model can process, making it the foundational first step for any AI task.","The process of converting data from a human-readable format (e.g., text, images, audio) into a numerical representation that a machine learning model can process.	","AI models operate on numbers, not raw data like pixels or characters. Encoding is the crucial bridge that translates real-world information into a mathematical format the model can process, making it the foundational first step for any AI task."
Remove,Pre training,Attention,"Mechanism that lets the model focus on relevant parts of the input ◆ This is a crucial ability for understanding language. It makes language models faster, more accurate and capable of capturing nuanced meaning.",Mechanism that lets the model focus on relevant parts of the input,"This is a crucial ability for understanding language. It makes language models faster, more accurate and capable of capturing nuanced meaning."
Pre training,Hamel's list,Distillation,"Making a smaller, faster model from a big one. ◆ It lets you use cheaper, faster models with less delay (latency). But the smaller model might not be as accurate or powerful as the big one. So, you trade some performance for speed and cost savings.","Making a smaller, faster model from a big one.","It lets you use cheaper, faster models with less delay (latency). But the smaller model might not be as accurate or powerful as the big one. So, you trade some performance for speed and cost savings."
Pre training,Hamel's list,Hyperparameters,"Settings that affect how the model works. ◆ These include the number of layers, vocabulary size, and dimensions of the model. By adjusting these settings, you can make the AI learn better. It often takes trying different options to find what works best.",Settings that affect how the model works.,"These include the number of layers, vocabulary size, and dimensions of the model. By adjusting these settings, you can make the AI learn better. It often takes trying different options to find what works best."
Pre training,Pre training,Knowledge cut-off,"The date beyond which a model has no information. ◆ This is a fundamental limitation of current LLMs, because they stop learning after training is complete. They don't have real-time knowledge unless they are augmented with tools like web search.",The date beyond which a model has no information.,"This is a fundamental limitation of current LLMs, because they stop learning after training is complete. They don't have real-time knowledge unless they are augmented with tools like web search."
Pre training,Pre training,Loss,A number that measures how wrong the model's predictions are during training. ◆ The goal of training is to minimize the loss. Watching the loss go down is how researchers know the model is learning.,A number that measures how wrong the model's predictions are during training.,The goal of training is to minimize the loss. Watching the loss go down is how researchers know the model is learning.
Pre training,Hamel's list,Multimodal,"Models that handle different data types like text and images. ◆ People use words, pictures, and sounds. When AI can understand all these, it can help users better. Using multimodal AI makes your tools more powerful.",Models that handle different data types like text and images.,"People use words, pictures, and sounds. When AI can understand all these, it can help users better. Using multimodal AI makes your tools more powerful."
Remove,Post training,Chains of Thought,"The process of having a model ""think out loud"" by generating the intermediate steps of reasoning required to solve a problem. ◆ This technique dramatically improves a model's performance on complex reasoning tasks by forcing it to slow down and show its work.","The process of having a model ""think out loud"" by generating the intermediate steps of reasoning required to solve a problem.",This technique dramatically improves a model's performance on complex reasoning tasks by forcing it to slow down and show its work.
Pre training,Pre training,Neural network architecture,"Design of the math functions that create the neural network ◆ It influences ability to learn, scalability, modalities, and training / inference cost. Breakthroughs here are big. Examples include Transformer, Mixture of Experts (MoE), State Space Models (SSMs), Multimodal / Unified, Matryoshka Representation, etc.",Design of the math functions that create the neural network,"It influences ability to learn, scalability, modalities, and training / inference cost. Breakthroughs here are big. Examples include Transformer, Mixture of Experts (MoE), State Space Models (SSMs), Multimodal / Unified, Matryoshka Representation, etc."
Pre training,Pre training,"Parameters
Rel: weights, model size","The learned ""long-term"" memory, represented as billions of numbers ◆ Providing more parameters allows training on more data and creating more capabilities. It's also slower and more expensive to train and run. Conversely, smaller models are cheaper and faster, but lesser capable.","The learned ""long-term"" memory, represented as billions of numbers","Providing more parameters allows training on more data and creating more capabilities. It's also slower and more expensive to train and run. Conversely, smaller models are cheaper and faster, but lesser capable."
Remove,Hamel's list,Context Window,The maximum text the model can use at once. ◆ The model has a limit on how much text it can handle. You need to manage this to fit important info.,The maximum text the model can use at once.,The model has a limit on how much text it can handle. You need to manage this to fit important info.
Remove,Reinforcement Learning (RL),Distillation risk,"The risk that a competitor could steal a model's advanced reasoning abilities by training their own model on its detailed outputs. ◆ This is why some companies hide the ""thinking"" process of their reasoning models, as it's a valuable and hard-won capability.",The risk that a competitor could steal a model's advanced reasoning abilities by training their own model on its detailed outputs.,"This is why some companies hide the ""thinking"" process of their reasoning models, as it's a valuable and hard-won capability."
Remove,Pre training,Embedding,The process of converting discrete tokens into continuous numerical vectors that the network can process. ◆ This allows the model to understand relationships between tokens and is the first step in processing input text.,The process of converting discrete tokens into continuous numerical vectors that the network can process.,This allows the model to understand relationships between tokens and is the first step in processing input text.
Pre training,Hamel's list,"Transformer
Rel: attention","The main type of neural network architecture used in AI today ◆ It provides the crucial ability for understanding language, letting the model focus on relevant parts of input. It makes language models faster, more accurate and capable of capturing nuanced meaning.",The main type of neural network architecture used in AI today,"It provides the crucial ability for understanding language, letting the model focus on relevant parts of input. It makes language models faster, more accurate and capable of capturing nuanced meaning."
Remove,Pre training,Few-shot prompt,A prompt that includes several examples of a task to guide the model on how to perform it correctly. ◆ It's a powerful technique for controlling model output and getting it to perform specific tasks without having to retrain it.,A prompt that includes several examples of a task to guide the model on how to perform it correctly.,It's a powerful technique for controlling model output and getting it to perform specific tasks without having to retrain it.
Remove,Post training,Supervised Fine-Tuning (SFT),"The process of continuing to train a base model on a smaller, high-quality dataset of example conversations. ◆ This is the primary method for teaching the model how to behave like a helpful assistant by showing it examples of ideal responses.","The process of continuing to train a base model on a smaller, high-quality dataset of example conversations.",This is the primary method for teaching the model how to behave like a helpful assistant by showing it examples of ideal responses.
Remove,Hamel's list,Function Calling,"Getting the model to trigger actions or code. ◆ Allows AI to interact with apps, making it useful for tasks like getting data or automating jobs.",Getting the model to trigger actions or code.,"Allows AI to interact with apps, making it useful for tasks like getting data or automating jobs."
Pre training,Pre training,Vocabulary,The complete set of unique tokens that a model can recognize and produce. ◆ The vocabulary defines the atomic units of language the model works with. Its size is a key design choice in an LLM's architecture.,The complete set of unique tokens that a model can recognize and produce.,The vocabulary defines the atomic units of language the model works with. Its size is a key design choice in an LLM's architecture.
Remove,Pre training,Hallucination,"When a model confidently generates incorrect or nonsensical information. ◆ This is a major reliability problem. The model doesn't ""know"" when it's making things up; it's just predicting the statistically likely next token.",When a model confidently generates incorrect or nonsensical information.,"This is a major reliability problem. The model doesn't ""know"" when it's making things up; it's just predicting the statistically likely next token."
Remove,Post training,Human labelers,"People hired to create the ideal conversational data used for SFT. ◆ They are the source of the ""good"" behavior that the model learns to imitate. The quality of their work directly shapes the AI's personality and helpfulness.",People hired to create the ideal conversational data used for SFT.,"They are the source of the ""good"" behavior that the model learns to imitate. The quality of their work directly shapes the AI's personality and helpfulness."
Post training,Hamel's list,Chain of Thought,"Prompting the model to think and plan before answering. ◆ When the model thinks first, it gives better answers but takes longer. This trade-off affects speed and quality.",Prompting the model to think and plan before answering.,"When the model thinks first, it gives better answers but takes longer. This trade-off affects speed and quality."
Remove,Pre training,Inference,"The process of using a fully trained model to generate new text by repeatedly predicting the next token in a sequence. ◆ This is what happens when you interact with a chatbot like ChatGPT. The model is no longer learning, only generating.",The process of using a fully trained model to generate new text by repeatedly predicting the next token in a sequence.,"This is what happens when you interact with a chatbot like ChatGPT. The model is no longer learning, only generating."
Post training,Hamel's list,Fine-Tuning,Adjusting a pre-trained model for a specific job. ◆ It helps make the AI better for your needs by teaching it with your data. But it might become less good at general tasks. Fine-tuning works best for specific jobs where you need higher accuracy.,Adjusting a pre-trained model for a specific job.,It helps make the AI better for your needs by teaching it with your data. But it might become less good at general tasks. Fine-tuning works best for specific jobs where you need higher accuracy.
Post training,Post training,"Tools
Rel: Tool use","Giving AI the ability to call external programs, like a web search, a calculator, a database, or a code interpreter. ◆ This overcomes the model's inherent limitations (like knowledge cut-offs or poor arithmetic) by allowing it to access real-time data and precise computation. Having tools to access the file system or databases can support the ""skill"" of programming.","Giving AI the ability to call external programs, like a web search, a calculator, a database, or a code interpreter.","This overcomes the model's inherent limitations (like knowledge cut-offs or poor arithmetic) by allowing it to access real-time data and precise computation. Having tools to access the file system or databases can support the ""skill"" of programming."
Remove,Pre training,"Layer norms, Matrix multiplications, Softmaxes","The fundamental mathematical operations that make up the layers of a Transformer network. ◆ These simple, repeated calculations, when performed at a massive scale, enable the complex processing that LLMs do.",The fundamental mathematical operations that make up the layers of a Transformer network.,"These simple, repeated calculations, when performed at a massive scale, enable the complex processing that LLMs do."
Remove,Reinforcement Learning (RL),LLM Judge,"Using a powerful LLM to automatically evaluate the quality of another LLM's output. ◆ This is a scalable way to get feedback for training, especially in domains that are hard to score with simple rules.",Using a powerful LLM to automatically evaluate the quality of another LLM's output.,"This is a scalable way to get feedback for training, especially in domains that are hard to score with simple rules."
Remove,Pre training,Logits / Softmax,The raw scores (logits) and resulting probabilities (softmax) that the model assigns to each possible next token. ◆ This output distribution represents the model's prediction. The model then samples from these probabilities to choose the next token.,The raw scores (logits) and resulting probabilities (softmax) that the model assigns to each possible next token.,This output distribution represents the model's prediction. The model then samples from these probabilities to choose the next token.
Post training,Hamel's list,Guardrails,Safety rules to control model outputs. ◆ Guardrails help reduce the chance of the AI giving bad or harmful answers. But they are not perfect. It’s important to use them wisely and not rely on them completely.,Safety rules to control model outputs.,Guardrails help reduce the chance of the AI giving bad or harmful answers. But they are not perfect. It’s important to use them wisely and not rely on them completely.
Remove,Pre training,Maximum context length,The maximum number of tokens the model can process at one time to make a prediction. ◆ This is a critical limitation. A longer context length allows the model to understand more complex documents and maintain longer conversations.,The maximum number of tokens the model can process at one time to make a prediction.,This is a critical limitation. A longer context length allows the model to understand more complex documents and maintain longer conversations.
Remove,Future Capabilities,Multimodal,"The ability for a single model to understand and generate information across multiple formats like text, images, and audio. ◆ This is the next major frontier, moving AI from text-only chatbots to assistants that can see, hear, and speak, making them far more versatile.","The ability for a single model to understand and generate information across multiple formats like text, images, and audio.","This is the next major frontier, moving AI from text-only chatbots to assistants that can see, hear, and speak, making them far more versatile."
Post training,Reinforcement Learning (RL),"Thinking model
Rel: reasoning model","A model that has undergone extensive RL, making it adept at complex, multi-step problem solving. ◆ These models represent the frontier of AI capabilities, moving from simple Q&A to genuine problem-solving.","A model that has undergone extensive RL, making it adept at complex, multi-step problem solving.","These models represent the frontier of AI capabilities, moving from simple Q&A to genuine problem-solving."
Post training,Reinforcement Learning (RL),"Reinforcement Learning (RL)
Rel: RLHF, RLAIF","Training by making the AI do exercises and learn from its mistakes ◆ RL allows the model to go beyond imitating human experts and discover novel, more effective strategies for solving problems on its own. This is how it acquired difficult skills like solving math problems, or writing code.

It can get the feedback from humans (RLHF) or from another AI model (RLAIF).",Training by making the AI do exercises and learn from its mistakes,"RL allows the model to go beyond imitating human experts and discover novel, more effective strategies for solving problems on its own. This is how it acquired difficult skills like solving math problems, or writing code.

It can get the feedback from humans (RLHF) or from another AI model (RLAIF)."
Remove,Hamel's list,Reinforcement Learning from Human Feedback (RLHF),"Training AI using people’s feedback. ◆ It helps the AI learn from what people like or don’t like, making its answers better. But it’s a complex method, and you might not need it right away.",Training AI using people’s feedback.,"It helps the AI learn from what people like or don’t like, making its answers better. But it’s a complex method, and you might not need it right away."
AI Engineering,Future Capabilities,Agents,AI systems that can autonomously perform a sequence of tasks over time to achieve a complex goal. ◆ Agents represent the shift from single-shot commands to having AI assistants that can manage long-running jobs and projects.,AI systems that can autonomously perform a sequence of tasks over time to achieve a complex goal.,Agents represent the shift from single-shot commands to having AI assistants that can manage long-running jobs and projects.
AI Engineering,Future Capabilities,Open weights model,"A model whose parameters are publicly released, allowing anyone to use, modify, and build upon it. ◆ This fosters innovation and competition, preventing the most powerful AI technology from being controlled by only a handful of large corporations.","A model whose parameters are publicly released, allowing anyone to use, modify, and build upon it.","This fosters innovation and competition, preventing the most powerful AI technology from being controlled by only a handful of large corporations."
Remove,Reinforcement Learning (RL),Reward model,"A model trained to predict which of two responses a human is likely to prefer. ◆ It acts as a scalable, automated proxy for human judgment, making it possible to apply RL to improve qualities like helpfulness and harmlessness.",A model trained to predict which of two responses a human is likely to prefer.,"It acts as a scalable, automated proxy for human judgment, making it possible to apply RL to improve qualities like helpfulness and harmlessness."
Remove,Post training,Special tokens,"New tokens added to the vocabulary to structure conversations, marking the beginning and end of turns for the user and assistant. ◆ They provide the necessary structure for the model to understand the format of a dialogue, which is different from the free-form text it saw in pre-training.","New tokens added to the vocabulary to structure conversations, marking the beginning and end of turns for the user and assistant.","They provide the necessary structure for the model to understand the format of a dialogue, which is different from the free-form text it saw in pre-training."
AI Engineering,,Context Engineering,"Context engineering is the art and science of strategically assembling all necessary information—such as task descriptions, few-shot examples, retrieved data (RAG), tools, and conversation history—into an LLM's context window to optimize its performance for the next step. ◆ An LLM's performance is critically dependent on the quality and relevance of the information in its context window. Providing too little information leads to poor results, while too much or irrelevant information increases costs and can degrade performance.","Context engineering is the art and science of strategically assembling all necessary information—such as task descriptions, few-shot examples, retrieved data (RAG), tools, and conversation history—into an LLM's context window to optimize its performance for the next step.","An LLM's performance is critically dependent on the quality and relevance of the information in its context window. Providing too little information leads to poor results, while too much or irrelevant information increases costs and can degrade performance."
,,,,,
AI Engineering,Hamel's list,Embeddings,"Turning words into numbers that show meaning. ◆ Embeddings let you search documents by meaning, not just exact words. This helps you find information even if different words are used, making searches smarter and more accurate.",Turning words into numbers that show meaning.,"Embeddings let you search documents by meaning, not just exact words. This helps you find information even if different words are used, making searches smarter and more accurate."
AI Engineering,Hamel's list,Few-Shot Learning,"Teaching the model with only a few examples. ◆ By giving the model examples, you can guide it to behave the way you want. It’s a simple but powerful way to teach the AI what is good or bad.",Teaching the model with only a few examples.,"By giving the model examples, you can guide it to behave the way you want. It’s a simple but powerful way to teach the AI what is good or bad."
AI Engineering,Hamel's list,Retrieval Augmented Generation (RAG),"Providing relevant context to the LLM. ◆ A language model needs proper context to answer questions. Like a person, it needs access to information such as data, past conversations, or documents to give a good answer. Collecting and giving this info to the AI before asking helps prevent mistakes or it saying, “I don’t know.”",Providing relevant context to the LLM.,"A language model needs proper context to answer questions. Like a person, it needs access to information such as data, past conversations, or documents to give a good answer. Collecting and giving this info to the AI before asking helps prevent mistakes or it saying, “I don’t know.”"
,,,,,
AI Engineering,Hamel's list,Temperature,A setting that controls how creative AI responses are. ◆ Lets you choose between predictable or more imaginative answers. Adjusting temperature can affect the quality and usefulness of the AI’s responses.,A setting that controls how creative AI responses are.,Lets you choose between predictable or more imaginative answers. Adjusting temperature can affect the quality and usefulness of the AI’s responses.
Remove,Reinforcement Learning (RL),Unverifiable domains,"Subjective tasks like writing a poem or a joke, where there is no single ""correct"" answer to check against. ◆ These domains pose a challenge for standard RL, which requires a clear reward signal.","Subjective tasks like writing a poem or a joke, where there is no single ""correct"" answer to check against.","These domains pose a challenge for standard RL, which requires a clear reward signal."
AI Engineering,Hamel's list,Top-p Sampling,Choosing the next word from top choices making up a set probability. ◆ Balances predictability and creativity in AI responses. The trade-off is between safe answers and more varied ones.,Choosing the next word from top choices making up a set probability.,Balances predictability and creativity in AI responses. The trade-off is between safe answers and more varied ones.
Remove,Reinforcement Learning (RL),Verifiable domains,"Tasks like math or coding, where a solution can be automatically and objectively checked for correctness. ◆ These are the ideal environments for RL because it's easy to provide the model with a clear success or failure signal.","Tasks like math or coding, where a solution can be automatically and objectively checked for correctness.",These are the ideal environments for RL because it's easy to provide the model with a clear success or failure signal.
AI Engineering,Hamel's list,Vector Database,"A special database for storing and searching embeddings. ◆ They store embeddings of text, images, and more, so you can search by meaning. This makes finding similar items faster and improves searches and recommendations.",A special database for storing and searching embeddings.,"They store embeddings of text, images, and more, so you can search by meaning. This makes finding similar items faster and improves searches and recommendations."
Remove,Hamel's list,Zero-Shot Learning,"When the model does a new task without training or examples. ◆ This means you don’t give any examples to the AI. While it’s good for simple tasks, not providing examples might make it harder for the AI to perform well on complex tasks. Giving examples helps, but takes up space in the prompt. You need to balance prompt space with the need for examples.",When the model does a new task without training or examples.,"This means you don’t give any examples to the AI. While it’s good for simple tasks, not providing examples might make it harder for the AI to perform well on complex tasks. Giving examples helps, but takes up space in the prompt. You need to balance prompt space with the need for examples."